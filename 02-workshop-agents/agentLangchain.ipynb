{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4881e7-23a6-4810-996c-8b014b6da53c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Workshop: Introducci√≥n a Generative AI en Oracle y Creaci√≥n de Agentes con LangChain\n",
    "\n",
    "Bienvenidos al workshop. En esta sesi√≥n vamos a explorar c√≥mo usar los **servicios de IA generativa de Oracle** para resolver problemas reales y luego **crear un agente inteligente** usando **LangChain** que pueda interactuar con estos servicios.\n",
    "\n",
    "## Objetivos de la sesi√≥n\n",
    "- Conocer la oferta de **Oracle Cloud Infrastructure (OCI Generative AI)** y c√≥mo integrarla desde Python.\n",
    "- Ejecutar peticiones a modelos de lenguaje para **generar texto** de manera controlada.\n",
    "- Construir un **agente con LangChain** que use herramientas  para responder preguntas de forma aut√≥noma.\n",
    "- Aprender buenas pr√°cticas para **orquestar flujos de trabajo** y extender capacidades de los modelos.\n",
    "\n",
    "## Requisitos previos\n",
    "- Conocimientos b√°sicos de Python üêç\n",
    "- Tener acceso a una cuenta de **Oracle Cloud** con permisos para usar **OCI Generative AI**\n",
    "- Familiaridad b√°sica con entornos virtuales y Jupyter Notebooks.\n",
    "\n",
    "> üí° **Tip:** este notebook est√° dise√±ado para ser pr√°ctico y paso a paso. Podr√°s copiar, ejecutar y modificar el c√≥digo para experimentar con los conceptos que vamos a explicar.\n",
    "\n",
    "¬°Vamos a empezar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ef975-2a11-4ae0-ae9e-1e5bde757e39",
   "metadata": {},
   "source": [
    "## A continuaci√≥n... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded46ce2-2c6d-4aff-9746-d224f6983d39",
   "metadata": {},
   "source": [
    "üì∞ Recopilaremos noticias sobre Innovaci√≥n y tecnolog√≠a chilena\n",
    "\n",
    "ü§ñ Consumiremos un modelo de lenguaje alojado en Oracle Cloud \n",
    "\n",
    "üîç Construiremos un agente con langchain que es capaz de responder a preguntas relacionadas con las StartUps, tecnolog√≠a, IA y futuro digital en Chile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc18161-3632-49e1-9871-7ca9d9b669d0",
   "metadata": {},
   "source": [
    "## Instalaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f36e7-d498-41a3-9bb1-cf9f537783f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain==0.3.20 langchain-oci==0.1.6 tavily-python oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9dda19-f7c5-4abd-9cff-0d4452b611a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64, pathlib\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def embed_png(path, width=520):\n",
    "    data = base64.b64encode(pathlib.Path(path).read_bytes()).decode(\"ascii\")\n",
    "    return HTML(f'<img src=\"data:image/png;base64,{data}\" width=\"{width}\">')\n",
    "\n",
    "display(HTML(\"<h3>ü™™ Registro en Tavily (paso a paso)</h3>\"))\n",
    "display(HTML(\"<p>1Ô∏è‚É£ Abre <a href='https://app.tavily.com/home' target='_blank'>https://app.tavily.com/home</a> y haz clic en <b>Sign Up</b>.</p>\"))\n",
    "display(embed_png(\"images/tavily_signup.png\"))\n",
    "display(HTML(\"<p>2Ô∏è‚É£ Inicia sesi√≥n y copia tu <b>API Key</b> desde la p√°gina principal.</p>\"))\n",
    "display(embed_png(\"images/api_key.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b62418-564b-4da4-a874-7e12aacf2c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pega la API Key de Tavily aqu√≠\n",
    "TAVILY_API_KEY = \"tvly-dev-RTqD...\"  # Reemplaza con tu API Key de Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8becbb39-3e30-4b1b-9f8c-667adab0c5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert TAVILY_API_KEY != \"pega_aqui_tu_api_key\", \"Por favor, pega tu API Key de Tavily en la variable TAVILY_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f2ffb-1322-4fe6-88b8-74feeb329ce4",
   "metadata": {},
   "source": [
    "## Configuraci√≥n de la autenticaci√≥n del SDK de OCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c0c19f-1988-4841-be1f-12a9449e0735",
   "metadata": {},
   "source": [
    "Desde este notebook es necesario acceder a algunos servicios de Oracle, como el servicio de Generative AI, aunque ejecutes este notebook en cloud o de forma local, es necesario configurar las credenciales en la m√°quina que realiza el consumo del servicio. \n",
    "\n",
    "```\n",
    "En los pasos anteriores fue necesario descargar un archivo terminado en .pem y copiar una configuraci√≥n con el siguiente estilo\n",
    "[DEFAULT]\n",
    "user=ocid1.user.oc1..\n",
    "fingerprint=95:e1:09\n",
    "tenancy=ocid1.tenancy.oc1..\n",
    "region= \n",
    "```\n",
    "\n",
    "A continuaci√≥n usaremos esos objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c3ca8-1faf-4921-ac06-1faf109ab257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# crea carpeta y permisos\n",
    "!mkdir -p /home/datascience/.oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11db8c2-2f3b-42cf-acdb-6e1da3235b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.oci\n",
    "!ls -la ~/.oci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b623b7-4724-4b1f-abdd-2776dae08cb9",
   "metadata": {},
   "source": [
    "Ahora vamos a ubicar la llave privada que descargamos en los pasos anteriores al generar el API Key. El archivo tendr√° un nombre similar a ‚Äútu_usuario-a√±o-mes-diaTHH_MM_SS.XXX.pem‚Äù.\n",
    "\n",
    "Este archivo debe renombrarse como ‚Äúoci_api_key.pem‚Äù y cargarse en Data Science utilizando la opci√≥n ‚ÄúUpload Files‚Äù, o bien arrastr√°ndolo directamente en el men√∫ izquierdo del navegador.\n",
    "\n",
    "Una vez que el archivo est√© cargado, podremos proceder con la ejecuci√≥n de la siguiente l√≠nea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81ded9-1169-4716-8d71-757b095c77a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mv ~/oci_api_key.pem ~/.oci/oci_api_key.pem\n",
    "!chmod 600 ~/.oci/oci_api_key.pem\n",
    "!ls -la ~/.oci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693430b-312a-4cb4-a7f1-818f7c43598d",
   "metadata": {},
   "source": [
    "A continuaci√≥n, crearemos el archivo de configuraci√≥n en la ruta ~/.oci/config, vamos a copiar los valores de la configuraci√≥n mostrada en pantalla y a reemplazarlos en la siguiente l√≠nea.\n",
    "\n",
    "Reemplazaremos _ocid1.user.oc1.._ por el ocid del usuario mostrado en pantalla\n",
    "Reemplazaremos _fingerprint_ por el figerprint mostrado en pantalla\n",
    "üö® No reemplazaremos _key_file_ por ninguna ruta si estamos ejecutando este notebook en DataScience. Si queremos ejecutar este notebook de forma local, podemos reemplazar la ruta por ~/.oci/nombre_de_la_key.pem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476c57d-435d-4bcc-9c52-5fc8c70e0946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ~/.oci/config <<'CFG'\n",
    "\n",
    "[DEFAULT]\n",
    "user=ocid1.user.oc1..aaaaa...\n",
    "fingerprint=ab:50:7a:...:..\n",
    "tenancy=ocid1.tenancy.oc1..aaaaaaa..\n",
    "region=us-chicago-1\n",
    "key_file=/home/datascience/.oci/oci_api_key.pem\n",
    "CFG\n",
    "\n",
    "echo \"Config creado en ~/.oci/config\"\n",
    "cat ~/.oci/config | sed 's/fingerprint=.*/fingerprint=<oculto>/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7daf90-dde6-47c8-bc22-694a4de1735b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Descomenta √∫nicamente la l√≠nea que corresponda a tu regi√≥n\n",
    "#REGION = \"sa-saopaulo-1\"\n",
    "REGION = \"us-chicago-1\"\n",
    "#REGION = \"uk-london-1\"\n",
    "#REGION = \"eu-frankfurt-1\"\n",
    "#REGION = \"ap-osaka-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571b32e-6d80-4bc2-ae92-a9945a51ab2f",
   "metadata": {},
   "source": [
    "## ü§ñ Creaci√≥n del Agente LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24af32-885f-4013-bcca-e9fdf16f8347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONFIGURACI√ìN DEL AGENTE LANGCHAIN + LLAMA 4\n",
    "from langchain_oci import ChatOCIGenAI\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Compartment ID en OCI ---\n",
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..aaaaaaa...\"  # Reemplaza con tu Compartment OCID\n",
    "\n",
    "# ID del modelo (Llama 4 Maverick)\n",
    "MODEL_ID = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyayjawvuonfkw2ua4bob4rlnnlhs522pafbglivtwlfzta\" #Llama 4 Maverick\n",
    "#MODEL_ID = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyarojgfh6msa452vziycwfymle5gxdvpwwxzara53topmq\" #Llama 4 Scout\n",
    "\n",
    "# Inicializamos el LLM\n",
    "llm = ChatOCIGenAI(\n",
    "    model_id=MODEL_ID,\n",
    "    service_endpoint=f\"https://inference.generativeai.{REGION}.oci.oraclecloud.com\",\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    "    provider=\"meta\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 800,\n",
    "        \"top_p\": 0.8\n",
    "    },\n",
    "    auth_type=\"API_KEY\",\n",
    "    auth_profile=\"DEFAULT\"\n",
    ")\n",
    "\n",
    "# Creamos una herramienta\n",
    "@tool\n",
    "def get_chilean_innovation_news(pregunta: str) -> str:\n",
    "    \"\"\"Busca informaci√≥n sobre innovaci√≥n, ciencia y tecnolog√≠a en Chile.\"\"\"\n",
    "    client = TavilyClient(TAVILY_API_KEY)\n",
    "    try:\n",
    "        response = client.search(query=pregunta, max_results=5)\n",
    "        results = response.get(\"results\", [])\n",
    "        formatted = \"\\n\".join([f\"- **{r['title']}** ({r['url']})\" for r in results])\n",
    "        return formatted if formatted else \"No se encontraron resultados relevantes.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error en la b√∫squeda: {e}\"\n",
    "\n",
    "tools = [get_chilean_innovation_news]\n",
    "\n",
    "# Plantilla ReAct\n",
    "react_prompt_template = \"\"\"Eres un experto en **innovaci√≥n y tecnolog√≠a chilena**.\n",
    "Usa las herramientas cuando aporten valor.\n",
    "Responde en espa√±ol neutro y con un tono profesional y actualizado.\n",
    "\n",
    "Herramientas disponibles:\n",
    "{tools}\n",
    "\n",
    "Formato:\n",
    "Question: la pregunta\n",
    "Thought: qu√© vas a hacer\n",
    "Action: una de [{tool_names}]\n",
    "Action Input: el input\n",
    "Observation: resultado\n",
    "Thought: analiza y sintetiza\n",
    "Final Answer: respuesta clara y √∫til.\n",
    "\n",
    "Empecemos.\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(react_prompt_template)\n",
    "\n",
    "# Construcci√≥n del agente\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Pregunta ---\n",
    "pregunta = \"¬øQu√© startups chilenas est√°n aplicando inteligencia artificial o tecnolog√≠as sostenibles en 2025?\"\n",
    "respuesta = agent_executor.invoke({\"input\": pregunta})\n",
    "\n",
    "print(\"\\n--- RESPUESTA DEL AGENTE ---\\n\")\n",
    "print(respuesta[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14b781-ebbc-4027-8ad5-465ef39e456b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_oci import ChatOCIGenAI\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "\n",
    "# --- Configuraci√≥n de OCI ---\n",
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..aaaaaaa...\"  # Reemplaza con tu Compartment OCID\n",
    "REGION = \"us-chicago-1\"\n",
    "\n",
    "MODEL_ID_LLAMA = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyayjawvuonfkw2ua4bob4rlnnlhs522pafbglivtwlfzta\" #Llama 4 Maverick\n",
    "\n",
    "\n",
    "# === LLM principal ===\n",
    "llm = ChatOCIGenAI(\n",
    "    model_id=MODEL_ID_LLAMA,\n",
    "    service_endpoint=f\"https://inference.generativeai.{REGION}.oci.oraclecloud.com\",\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    "    provider=\"meta\",\n",
    "    model_kwargs={\"temperature\": 0.3, \"max_tokens\": 800, \"top_p\": 0.8},\n",
    "    auth_type=\"API_KEY\",\n",
    "    auth_profile=\"DEFAULT\"\n",
    ")\n",
    "\n",
    "# === Herramienta ===\n",
    "@tool\n",
    "def get_chilean_innovation_news(pregunta: str) -> str:\n",
    "    \"\"\"Busca informaci√≥n sobre innovaci√≥n, ciencia y tecnolog√≠a en Chile.\"\"\"\n",
    "    try:\n",
    "        client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "        response = client.search(query=pregunta, max_results=5)\n",
    "        results = response.get(\"results\", [])\n",
    "        if not results:\n",
    "            return \"No se encontraron resultados relevantes.\"\n",
    "        formatted = \"\\n\".join([f\"- **{r['title']}** ({r['url']})\" for r in results])\n",
    "        return formatted\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error al realizar la b√∫squeda: {e}\"\n",
    "\n",
    "tools = [get_chilean_innovation_news]\n",
    "\n",
    "# === Prompt del agente ReAct ===\n",
    "react_prompt_template = \"\"\"Eres un experto en innovaci√≥n, ciencia y tecnolog√≠a chilena.\n",
    "Usa las herramientas cuando sea necesario. Responde en espa√±ol neutro, tono profesional.\n",
    "\n",
    "Herramientas disponibles:\n",
    "{tools}\n",
    "\n",
    "Formato EXACTO:\n",
    "Question: la pregunta\n",
    "Thought: qu√© vas a hacer\n",
    "Action: una de [{tool_names}]\n",
    "Action Input: el input\n",
    "Observation: resultado\n",
    "Thought: analiza y sintetiza\n",
    "Final Answer: respuesta clara y √∫til.\n",
    "\n",
    "Empecemos.\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(react_prompt_template)\n",
    "\n",
    "# === Construcci√≥n del agente ===\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# === Ejecuci√≥n del agente ===\n",
    "pregunta = \"¬øQu√© startups chilenas est√°n aplicando inteligencia artificial o tecnolog√≠as sostenibles en 2025?\"\n",
    "#pregunta = \"¬øCu√°les son las √∫ltimas tendencias en innovaci√≥n tecnol√≥gica en Chile?\"\n",
    "#pregunta = \"Qu√© es el EVIC de la U de Los Andes?\"\n",
    "#pregunta = \"¬øQu√© impacto ha tenido la pandemia en la innovaci√≥n en Chile?\"\n",
    "respuesta = agent_executor.invoke({\"input\": pregunta})\n",
    "texto_base = respuesta[\"output\"]\n",
    "\n",
    "# --- Post-procesamiento con formato Markdown ---\n",
    "analysis_prompt = f\"\"\"\n",
    "Convierte el siguiente texto en una respuesta en **formato Markdown profesional**:\n",
    "\n",
    "TEXTO:\n",
    "{texto_base}\n",
    "\n",
    "Debes estructurarlo as√≠:\n",
    "\n",
    "## üß† Resumen general\n",
    "Breve descripci√≥n en 3‚Äì5 l√≠neas.\n",
    "\n",
    "## üöÄ Startups chilenas destacadas\n",
    "Lista de empresas, sector y tecnolog√≠a (en bullets).\n",
    "\n",
    "## üå± Tecnolog√≠as o tendencias clave\n",
    "Breve an√°lisis sobre innovaci√≥n, IA o sostenibilidad.\n",
    "\n",
    "## üîç Conclusi√≥n\n",
    "Resumen final con enfoque estrat√©gico o impacto pa√≠s.\n",
    "\n",
    "Formato Markdown claro, limpio y con √≠conos donde apliquen.\n",
    "\"\"\"\n",
    "\n",
    "# Llama 4 vuelve a dar formato\n",
    "formatted = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "\n",
    "display(Markdown(formatted.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034c0f6-c2b9-41c5-8164-d5aba8739cd3",
   "metadata": {},
   "source": [
    "## Agente usando Grok 4 fast razoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64d616-525c-4892-ad55-08c017e31332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_oci import ChatOCIGenAI\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from tavily import TavilyClient\n",
    "\n",
    "\n",
    "# CONFIGURACI√ìN OCI\n",
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..aaaaaa...\"  # Reemplaza con tu Compartment OCID\n",
    "REGION = \"us-chicago-1\"\n",
    "\n",
    "MODEL_ID = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyat2iycf2rksgjhlmrmsxakcyjbpxurwmfguxjzptogvqa\"\n",
    "\n",
    "\n",
    "# WRAPPER PARA GROK (Un traductor entre LangChain y Grok) m√°s seguro\n",
    "class GrokSafeChat(ChatOCIGenAI):\n",
    "    def _get_model_kwargs(self, **kwargs):\n",
    "        kwargs.pop(\"stop\", None)\n",
    "        return super()._get_model_kwargs(**kwargs)\n",
    "\n",
    "llm = GrokSafeChat(\n",
    "    model_id=MODEL_ID,\n",
    "    service_endpoint=f\"https://inference.generativeai.{REGION}.oci.oraclecloud.com\",\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    "    provider=\"meta\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 1000\n",
    "    },\n",
    "    auth_type=\"API_KEY\",\n",
    "    auth_profile=\"DEFAULT\"\n",
    ")\n",
    "\n",
    "# TOOL DE B√öSQUEDA\n",
    "@tool\n",
    "def get_chilean_innovation_news(pregunta: str) -> str:\n",
    "    \"\"\"Busca noticias sobre innovaci√≥n tecnol√≥gica chilena.\"\"\"\n",
    "    client = TavilyClient(TAVILY_API_KEY)\n",
    "    try:\n",
    "        response = client.search(query=pregunta, max_results=5)\n",
    "        results = response.get(\"results\", [])\n",
    "        return \"\\n\".join([f\"- {r['title']} ({r['url']})\" for r in results]) \\\n",
    "               if results else \"No se encontraron resultados.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "tools = [get_chilean_innovation_news]\n",
    "\n",
    "\n",
    "# PROMPT COMPATIBLE CON GROK\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Eres un experto en innovaci√≥n, tecnolog√≠a y sostenibilidad chilena.\n",
    "Usa herramientas cuando aporten valor.\n",
    "Responde en espa√±ol claro, profesional y actualizado.\n",
    "\n",
    "Pregunta:\n",
    "{input}\n",
    "\n",
    "Razonamiento interno:\n",
    "{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# AGENTE\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# EJECUCI√ìN\n",
    "pregunta = \"¬øQu√© startups chilenas est√°n usando inteligencia artificial o tecnolog√≠as sostenibles en 2025?\"\n",
    "respuesta = agent_executor.invoke({\"input\": pregunta})\n",
    "texto_base = respuesta[\"output\"]\n",
    "\n",
    "print(\"\\n--- RESPUESTA DEL AGENTE GROK-4 ---\\n\")\n",
    "print(texto_base)\n",
    "\n",
    "\n",
    "# FORMATEO MARKDOWN\n",
    "\n",
    "analysis_prompt = f\"\"\"\n",
    "Convierte el siguiente texto en una respuesta en **formato Markdown profesional**:\n",
    "\n",
    "TEXTO:\n",
    "{texto_base}\n",
    "\n",
    "Debes estructurarlo as√≠:\n",
    "\n",
    "## üß† Resumen general\n",
    "Breve descripci√≥n en 3‚Äì5 l√≠neas.\n",
    "\n",
    "## üöÄ Startups chilenas destacadas\n",
    "Lista de empresas, sector y tecnolog√≠a (en bullets).\n",
    "\n",
    "## üå± Tecnolog√≠as o tendencias clave\n",
    "Breve an√°lisis sobre innovaci√≥n, IA o sostenibilidad.\n",
    "\n",
    "## üîç Conclusi√≥n\n",
    "Resumen final con enfoque estrat√©gico o impacto pa√≠s.\n",
    "\n",
    "Formato Markdown claro, limpio y con √≠conos donde apliquen.\n",
    "\"\"\"\n",
    "\n",
    "# Llamada directa al modelo\n",
    "formatted = llm.invoke([\n",
    "    HumanMessage(content=analysis_prompt)\n",
    "])\n",
    "\n",
    "\n",
    "# DISPLAY EN NOTEBOOK\n",
    "\n",
    "display(Markdown(formatted.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787c9aa-7989-479c-b8ae-03e6ce6ca1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_oci import ChatOCIGenAI\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from tavily import TavilyClient\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# CONFIGURACI√ìN OCI\n",
    "\n",
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..aaaaaaaap...\"  # Reemplaza con tu Compartment OCID\n",
    "REGION = \"us-chicago-1\"\n",
    "MODEL_ID = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyat2iycf2rksgjhlmrmsxakcyjbpxurwmfguxjzptogvqa\"\n",
    "\n",
    "\n",
    "# WRAPPER PARA GROK\n",
    "\n",
    "class GrokSafeChat(ChatOCIGenAI):\n",
    "    def _get_model_kwargs(self, **kwargs):\n",
    "        kwargs.pop(\"stop\", None)\n",
    "        return super()._get_model_kwargs(**kwargs)\n",
    "\n",
    "llm = GrokSafeChat(\n",
    "    model_id=MODEL_ID,\n",
    "    service_endpoint=f\"https://inference.generativeai.{REGION}.oci.oraclecloud.com\",\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    "    provider=\"meta\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 1000\n",
    "    },\n",
    "    auth_type=\"API_KEY\",\n",
    "    auth_profile=\"DEFAULT\"\n",
    ")\n",
    "\n",
    "\n",
    "# TOOL: BUSQUEDA EXTERNA\n",
    "@tool\n",
    "def get_chilean_innovation_news(pregunta: str) -> str:\n",
    "    \"\"\"Busca informaci√≥n p√∫blica sobre innovaci√≥n en Chile.\"\"\"\n",
    "    client = TavilyClient(TAVILY_API_KEY)\n",
    "    try:\n",
    "        response = client.search(query=pregunta, max_results=5)\n",
    "        results = response.get(\"results\", [])\n",
    "        return \"\\n\".join([f\"- {r['title']} ({r['url']})\" for r in results]) \\\n",
    "            if results else \"No se encontraron resultados.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "# TOOL: DETECT INTENT\n",
    "@tool\n",
    "def detect_intent(question: str) -> str:\n",
    "    \"\"\"Detecta intenci√≥n de la pregunta.\"\"\"\n",
    "    q = question.lower()\n",
    "\n",
    "    if any(p in q for p in [\"qui√©n es\", \"quien es\", \"participa\", \"perfil\", \"trabaja en\"]):\n",
    "        return \"persona\"\n",
    "\n",
    "    if any(p in q for p in [\"evento\", \"evic\", \"congreso\", \"seminario\"]):\n",
    "        return \"evento\"\n",
    "\n",
    "    if any(p in q for p in [\"startup\", \"empresa\", \"emprendimiento\"]):\n",
    "        return \"startup\"\n",
    "\n",
    "    return \"general\"\n",
    "\n",
    "\n",
    "# PROMPT PARA EL AGENTE\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Eres un asistente experto en innovaci√≥n chilena.\n",
    "\n",
    "Reglas:\n",
    "- Si la pregunta requiere informaci√≥n actual o p√∫blica, debes usar la herramienta.\n",
    "- Si no es necesario, responde normalmente.\n",
    "\n",
    "Pregunta:\n",
    "{input}\n",
    "\n",
    "Razonamiento:\n",
    "{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# AGENTE\n",
    "tools = [get_chilean_innovation_news]\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# EJECUCI√ìN\n",
    "#pregunta = \"¬øQu√© startups chilenas est√°n usando inteligencia artificial en 2025?\"\n",
    "#pregunta = \"¬øKarina Galindez participa en el EVIC 2025?\"\n",
    "pregunta = \"¬øCarla Vairetti participa en el EVIC 2025?\"\n",
    "\n",
    "# 1. Detectar intenci√≥n\n",
    "intent = detect_intent.run(pregunta)\n",
    "\n",
    "print(\"\\n--- INTENT DETECTADO ---\")\n",
    "print(intent)\n",
    "\n",
    "# 2. Decidir si usar tool\n",
    "usar_tool = any([\n",
    "    intent in [\"startup\", \"evento\"],\n",
    "    any(word in pregunta.lower() for word in [\"2025\", \"2024\", \"actual\", \"√∫ltimo\"]),\n",
    "    any(word in pregunta.lower() for word in [\"participa\", \"qui√©n\", \"quien\"])\n",
    "])\n",
    "\n",
    "\n",
    "# 3. Ejecutar\n",
    "if usar_tool:\n",
    "    respuesta = agent_executor.invoke({\"input\": pregunta})\n",
    "    texto_base = respuesta[\"output\"]\n",
    "else:\n",
    "    raw = llm.invoke([HumanMessage(content=pregunta)])\n",
    "    texto_base = raw.content\n",
    "\n",
    "print(\"\\n--- RESPUESTA DEL AGENTE ---\\n\")\n",
    "print(texto_base)\n",
    "\n",
    "\n",
    "# ETAPA MARKDOWN\n",
    "analysis_prompt = f\"\"\"\n",
    "Convierte el siguiente texto en una respuesta en **formato Markdown profesional**:\n",
    "\n",
    "TEXTO:\n",
    "{texto_base}\n",
    "\n",
    "Estructura:\n",
    "\n",
    "## üß† Resumen general\n",
    "3‚Äì5 l√≠neas.\n",
    "\n",
    "## üöÄ Puntos clave\n",
    "Bullets claros.\n",
    "\n",
    "## üå± Tendencias o tecnolog√≠as\n",
    "Breve an√°lisis.\n",
    "\n",
    "## üîç Conclusi√≥n\n",
    "Enfoque estrat√©gico.\n",
    "\n",
    " Usa √≠conos y formato limpio.\n",
    "\"\"\"\n",
    "\n",
    "formatted = llm.invoke([\n",
    "    HumanMessage(content=analysis_prompt)\n",
    "])\n",
    "\n",
    "# DISPLAY\n",
    "display(Markdown(formatted.content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
